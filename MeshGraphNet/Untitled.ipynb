{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dd6ba45-626b-48d7-9ff8-934c9f7cfc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeshGraphNets for Elastoplastic Dynamics\n",
      "============================================================\n",
      "Model created with 514306 parameters\n",
      "Predictions shape: torch.Size([100, 2])\n",
      "Loss: 1.6166\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MeshGraphNets implementation adapted for elastoplastic dynamics simulations.\n",
    "\n",
    "Key adaptations from original MeshGraphNets:\n",
    "- Computes edge features from node positions (no pre-computed edge_attr)\n",
    "- Removes node type one-hot encoding and associated loss masking\n",
    "- Handles 4 node features: [x_pos, y_pos, U_x, U_y]\n",
    "- Predicts 2 targets: [ΔU_x, ΔU_y]\n",
    "- Uses mesh_id for operator caching compatibility\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, ReLU, LayerNorm\n",
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "\n",
    "class ProcessorLayer(MessagePassing):\n",
    "    \"\"\"\n",
    "    Message passing layer for MeshGraphNets.\n",
    "    \n",
    "    Updates both edge and node embeddings through graph message passing.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(ProcessorLayer, self).__init__(**kwargs)\n",
    "        \n",
    "        # Edge processor: takes [sender_emb, receiver_emb, edge_emb]\n",
    "        self.edge_mlp = Sequential(\n",
    "            Linear(3 * in_channels, out_channels),\n",
    "            ReLU(),\n",
    "            Linear(out_channels, out_channels),\n",
    "            LayerNorm(out_channels)\n",
    "        )\n",
    "        \n",
    "        # Node processor: takes [node_emb, aggregated_messages]\n",
    "        self.node_mlp = Sequential(\n",
    "            Linear(2 * in_channels, out_channels),\n",
    "            ReLU(),\n",
    "            Linear(out_channels, out_channels),\n",
    "            LayerNorm(out_channels)\n",
    "        )\n",
    "        \n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reset parameters for stacked MLP layers\"\"\"\n",
    "        self.edge_mlp[0].reset_parameters()\n",
    "        self.edge_mlp[2].reset_parameters()\n",
    "        self.node_mlp[0].reset_parameters()\n",
    "        self.node_mlp[2].reset_parameters()\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr, size=None):\n",
    "        \"\"\"\n",
    "        Forward pass with message passing.\n",
    "        \n",
    "        Args:\n",
    "            x: Node embeddings [num_nodes, in_channels]\n",
    "            edge_index: Edge connectivity [2, num_edges]\n",
    "            edge_attr: Edge embeddings [num_edges, in_channels]\n",
    "            size: Optional size for bipartite graphs\n",
    "            \n",
    "        Returns:\n",
    "            updated_nodes: Updated node embeddings\n",
    "            updated_edges: Updated edge embeddings\n",
    "        \"\"\"\n",
    "        # Propagate messages and update edges\n",
    "        out, updated_edges = self.propagate(\n",
    "            edge_index, x=x, edge_attr=edge_attr, size=size\n",
    "        )\n",
    "        \n",
    "        # Aggregate with self-connection\n",
    "        updated_nodes = torch.cat([x, out], dim=1)\n",
    "        \n",
    "        # Apply MLP with residual connection\n",
    "        updated_nodes = x + self.node_mlp(updated_nodes)\n",
    "        \n",
    "        return updated_nodes, updated_edges\n",
    "    \n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        \"\"\"\n",
    "        Construct messages from sender to receiver.\n",
    "        \n",
    "        Args:\n",
    "            x_i: Sender node embeddings [num_edges, in_channels]\n",
    "            x_j: Receiver node embeddings [num_edges, in_channels]\n",
    "            edge_attr: Edge embeddings [num_edges, in_channels]\n",
    "            \n",
    "        Returns:\n",
    "            updated_edges: Updated edge embeddings with residual\n",
    "        \"\"\"\n",
    "        # Concatenate sender, receiver, and edge embeddings\n",
    "        updated_edges = torch.cat([x_i, x_j, edge_attr], dim=1)\n",
    "        \n",
    "        # Apply edge MLP with residual connection\n",
    "        updated_edges = self.edge_mlp(updated_edges) + edge_attr\n",
    "        \n",
    "        return updated_edges\n",
    "    \n",
    "    #def aggregate(self, updated_edges, edge_index, dim_size=None):\n",
    "    #    \"\"\"\n",
    "    #    Aggregate messages from neighboring nodes.\n",
    "    #    \n",
    "    #    Args:\n",
    "    #        updated_edges: Updated edge embeddings\n",
    "    #        edge_index: Edge connectivity\n",
    "    #        dim_size: Number of nodes\n",
    "    #        \n",
    "    #    Returns:\n",
    "    #        out: Aggregated messages per node\n",
    "    #        updated_edges: Updated edge embeddings (passed through)\n",
    "    #    \"\"\"\n",
    "    #    node_dim = 0  # Dimension along which to aggregate\n",
    "    #    \n",
    "    #    # Sum aggregation over incoming edges\n",
    "    #    out = torch_scatter.scatter(\n",
    "    #        updated_edges, \n",
    "    #        edge_index[0, :], \n",
    "    #        dim=node_dim, \n",
    "    #        reduce='sum'\n",
    "    #    )\n",
    "    #    \n",
    "    #    return out, updated_edges\n",
    "    def aggregate(self, updated_edges, edge_index, dim_size=None):\n",
    "        \"\"\"\n",
    "        Aggregate messages from neighboring nodes using native PyTorch.\n",
    "        \"\"\"\n",
    "        # edge_index[0, :] are the destination/target indices\n",
    "        target_index = edge_index[0, :]\n",
    "        \n",
    "        # Get the number of nodes (dim_size) if not provided\n",
    "        if dim_size is None:\n",
    "            dim_size = target_index.max().item() + 1 if target_index.numel() > 0 else 0\n",
    "    \n",
    "        # Initialize the output tensor on the same device as the edges\n",
    "        out = torch.zeros((dim_size, updated_edges.size(-1)), \n",
    "                          device=updated_edges.device, \n",
    "                          dtype=updated_edges.dtype)\n",
    "    \n",
    "        # Use index_add_ to perform the sum aggregation\n",
    "        # This is the native version of scatter(reduce='sum')\n",
    "        out.index_add_(0, target_index, updated_edges)\n",
    "        \n",
    "        return out, updated_edges\n",
    "\n",
    "\n",
    "class MeshGraphNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    MeshGraphNets model for elastoplastic dynamics.\n",
    "    \n",
    "    Architecture:\n",
    "    1. Encoder: Separate MLPs for nodes and edges\n",
    "    2. Processor: Stack of message passing layers\n",
    "    3. Decoder: MLP for node predictions\n",
    "    \n",
    "    Args:\n",
    "        input_dim_node: Number of node features (4: x_pos, y_pos, U_x, U_y)\n",
    "        input_dim_edge: Number of edge features (computed from positions)\n",
    "        hidden_dim: Hidden dimension for all MLPs (default: 128)\n",
    "        output_dim: Number of output features (2: ΔU_x, ΔU_y)\n",
    "        num_layers: Number of message passing layers (default: 10)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim_node, input_dim_edge, hidden_dim=128, \n",
    "                 output_dim=2, num_layers=10):\n",
    "        super(MeshGraphNet, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Encoder: Convert raw features to latent embeddings\n",
    "        self.node_encoder = Sequential(\n",
    "            Linear(input_dim_node, hidden_dim),\n",
    "            ReLU(),\n",
    "            Linear(hidden_dim, hidden_dim),\n",
    "            LayerNorm(hidden_dim)\n",
    "        )\n",
    "        \n",
    "        self.edge_encoder = Sequential(\n",
    "            Linear(input_dim_edge, hidden_dim),\n",
    "            ReLU(),\n",
    "            Linear(hidden_dim, hidden_dim),\n",
    "            LayerNorm(hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Processor: Stack of message passing layers\n",
    "        self.processor = nn.ModuleList([\n",
    "            ProcessorLayer(hidden_dim, hidden_dim)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Decoder: Convert node embeddings to predictions\n",
    "        self.decoder = Sequential(\n",
    "            Linear(hidden_dim, hidden_dim),\n",
    "            ReLU(),\n",
    "            Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "    \n",
    "    def _compute_edge_features(self, pos, edge_index):\n",
    "        \"\"\"\n",
    "        Compute edge features from node positions.\n",
    "        \n",
    "        For elastoplastic simulations, edge features are:\n",
    "        - Relative position: (pos_j - pos_i)\n",
    "        - Distance: ||pos_j - pos_i||\n",
    "        \n",
    "        Args:\n",
    "            pos: Node positions [num_nodes, 2]\n",
    "            edge_index: Edge connectivity [2, num_edges]\n",
    "            \n",
    "        Returns:\n",
    "            edge_attr: Edge features [num_edges, 3] (dx, dy, distance)\n",
    "        \"\"\"\n",
    "        # Get sender and receiver positions\n",
    "        row, col = edge_index\n",
    "        pos_i = pos[row]  # Sender positions\n",
    "        pos_j = pos[col]  # Receiver positions\n",
    "        \n",
    "        # Compute relative positions\n",
    "        rel_pos = pos_j - pos_i  # [num_edges, 2]\n",
    "        \n",
    "        # Compute distances\n",
    "        distance = torch.norm(rel_pos, dim=1, keepdim=True)  # [num_edges, 1]\n",
    "        \n",
    "        # Concatenate: [dx, dy, distance]\n",
    "        edge_attr = torch.cat([rel_pos, distance], dim=1)\n",
    "        \n",
    "        return edge_attr\n",
    "    \n",
    "    def forward(self, data, mean_vec_x=None, std_vec_x=None, \n",
    "                mean_vec_edge=None, std_vec_edge=None):\n",
    "        \"\"\"\n",
    "        Forward pass through MeshGraphNets.\n",
    "        \n",
    "        Args:\n",
    "            data: PyG Data object with attributes:\n",
    "                - x: Node features [num_nodes, 4]\n",
    "                - pos: Node positions [num_nodes, 2]\n",
    "                - edge_index: Edge connectivity [2, num_edges]\n",
    "            mean_vec_x: Mean for node feature normalization (optional)\n",
    "            std_vec_x: Std for node feature normalization (optional)\n",
    "            mean_vec_edge: Mean for edge feature normalization (optional)\n",
    "            std_vec_edge: Std for edge feature normalization (optional)\n",
    "            \n",
    "        Returns:\n",
    "            predictions: Predicted displacement increments [num_nodes, 2]\n",
    "        \"\"\"\n",
    "        x = data.x\n",
    "        pos = data.pos\n",
    "        edge_index = data.edge_index\n",
    "        \n",
    "        # Compute edge features from positions\n",
    "        edge_attr = self._compute_edge_features(pos, edge_index)\n",
    "        \n",
    "        # Normalize features if statistics provided\n",
    "        if mean_vec_x is not None and std_vec_x is not None:\n",
    "            x = (x - mean_vec_x) / std_vec_x\n",
    "        \n",
    "        if mean_vec_edge is not None and std_vec_edge is not None:\n",
    "            edge_attr = (edge_attr - mean_vec_edge) / std_vec_edge\n",
    "        \n",
    "        # Step 1: Encode node and edge features into latent embeddings\n",
    "        x = self.node_encoder(x)\n",
    "        edge_attr = self.edge_encoder(edge_attr)\n",
    "        \n",
    "        # Step 2: Message passing through processor layers\n",
    "        for processor_layer in self.processor:\n",
    "            x, edge_attr = processor_layer(x, edge_index, edge_attr)\n",
    "        \n",
    "        # Step 3: Decode node embeddings to predictions\n",
    "        predictions = self.decoder(x)\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def loss(self, pred, targets, mean_vec_y=None, std_vec_y=None):\n",
    "        \"\"\"\n",
    "        Compute L2 loss between predictions and targets.\n",
    "        \n",
    "        Args:\n",
    "            pred: Predicted displacement increments [num_nodes, 2]\n",
    "            targets: Target displacement increments [num_nodes, 2]\n",
    "            mean_vec_y: Mean for target normalization (optional)\n",
    "            std_vec_y: Std for target normalization (optional)\n",
    "            \n",
    "        Returns:\n",
    "            loss: Root mean squared error\n",
    "        \"\"\"\n",
    "        # Normalize targets if statistics provided\n",
    "        if mean_vec_y is not None and std_vec_y is not None:\n",
    "            targets = (targets - mean_vec_y) / std_vec_y\n",
    "        \n",
    "        # Compute squared error\n",
    "        error = torch.sum((targets - pred) ** 2, dim=1)\n",
    "        \n",
    "        # Return RMSE\n",
    "        loss = torch.sqrt(torch.mean(error))\n",
    "        \n",
    "        return loss\n",
    "\n",
    "\n",
    "def normalize(to_normalize, mean_vec, std_vec):\n",
    "    \"\"\"Normalize tensor using mean and standard deviation.\"\"\"\n",
    "    return (to_normalize - mean_vec) / std_vec\n",
    "\n",
    "\n",
    "def unnormalize(to_unnormalize, mean_vec, std_vec):\n",
    "    \"\"\"Unnormalize tensor using mean and standard deviation.\"\"\"\n",
    "    return to_unnormalize * std_vec + mean_vec\n",
    "\n",
    "\n",
    "def compute_stats(dataset, max_samples=None):\n",
    "    \"\"\"\n",
    "    Compute normalization statistics from dataset.\n",
    "    \n",
    "    Args:\n",
    "        dataset: ElastoPlasticDataset or list of sequences\n",
    "        max_samples: Maximum number of samples to use for statistics\n",
    "        \n",
    "    Returns:\n",
    "        stats_dict: Dictionary with mean and std for x, edge_attr, and y\n",
    "    \"\"\"\n",
    "    all_x = []\n",
    "    all_edge_attr = []\n",
    "    all_y = []\n",
    "    \n",
    "    print(\"Computing normalization statistics...\")\n",
    "    \n",
    "    sample_count = 0\n",
    "    for sequence in dataset:\n",
    "        for data in sequence:\n",
    "            all_x.append(data.x)\n",
    "            all_y.append(data.y)\n",
    "            \n",
    "            # Compute edge attributes\n",
    "            pos = data.pos\n",
    "            edge_index = data.edge_index\n",
    "            row, col = edge_index\n",
    "            rel_pos = pos[col] - pos[row]\n",
    "            distance = torch.norm(rel_pos, dim=1, keepdim=True)\n",
    "            edge_attr = torch.cat([rel_pos, distance], dim=1)\n",
    "            all_edge_attr.append(edge_attr)\n",
    "            \n",
    "            sample_count += 1\n",
    "            if max_samples is not None and sample_count >= max_samples:\n",
    "                break\n",
    "        \n",
    "        if max_samples is not None and sample_count >= max_samples:\n",
    "            break\n",
    "    \n",
    "    # Concatenate all features\n",
    "    all_x = torch.cat(all_x, dim=0)\n",
    "    all_edge_attr = torch.cat(all_edge_attr, dim=0)\n",
    "    all_y = torch.cat(all_y, dim=0)\n",
    "    \n",
    "    # Compute statistics\n",
    "    mean_vec_x = all_x.mean(dim=0)\n",
    "    std_vec_x = torch.maximum(all_x.std(dim=0), torch.tensor(1e-8))\n",
    "    \n",
    "    mean_vec_edge = all_edge_attr.mean(dim=0)\n",
    "    std_vec_edge = torch.maximum(all_edge_attr.std(dim=0), torch.tensor(1e-8))\n",
    "    \n",
    "    mean_vec_y = all_y.mean(dim=0)\n",
    "    std_vec_y = torch.maximum(all_y.std(dim=0), torch.tensor(1e-8))\n",
    "    \n",
    "    stats_dict = {\n",
    "        'mean_vec_x': mean_vec_x,\n",
    "        'std_vec_x': std_vec_x,\n",
    "        'mean_vec_edge': mean_vec_edge,\n",
    "        'std_vec_edge': std_vec_edge,\n",
    "        'mean_vec_y': mean_vec_y,\n",
    "        'std_vec_y': std_vec_y\n",
    "    }\n",
    "    \n",
    "    print(f\"Statistics computed from {sample_count} samples\")\n",
    "    print(f\"  Node features: mean={mean_vec_x}, std={std_vec_x}\")\n",
    "    print(f\"  Edge features: mean={mean_vec_edge}, std={std_vec_edge}\")\n",
    "    print(f\"  Targets: mean={mean_vec_y}, std={std_vec_y}\")\n",
    "    \n",
    "    return stats_dict\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    print(\"MeshGraphNets for Elastoplastic Dynamics\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create dummy data for testing\n",
    "    num_nodes = 100\n",
    "    num_edges = 500\n",
    "    \n",
    "    from torch_geometric.data import Data\n",
    "    \n",
    "    data = Data(\n",
    "        x=torch.randn(num_nodes, 4),  # [x_pos, y_pos, U_x, U_y]\n",
    "        pos=torch.randn(num_nodes, 2),  # [x, y]\n",
    "        edge_index=torch.randint(0, num_nodes, (2, num_edges)),\n",
    "        y=torch.randn(num_nodes, 2)  # [ΔU_x, ΔU_y]\n",
    "    )\n",
    "    \n",
    "    # Create model\n",
    "    model = MeshGraphNet(\n",
    "        input_dim_node=4,\n",
    "        input_dim_edge=3,  # [dx, dy, distance]\n",
    "        hidden_dim=128,\n",
    "        output_dim=2,\n",
    "        num_layers=4\n",
    "    )\n",
    "    \n",
    "    print(f\"Model created with {sum(p.numel() for p in model.parameters())} parameters\")\n",
    "    \n",
    "    # Forward pass\n",
    "    predictions = model(data)\n",
    "    print(f\"Predictions shape: {predictions.shape}\")\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = model.loss(predictions, data.y)\n",
    "    print(f\"Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32080bba-c9df-44fc-aaf6-2d636a971bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
